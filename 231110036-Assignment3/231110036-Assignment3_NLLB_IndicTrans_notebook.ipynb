{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:13:51.016383Z",
     "iopub.status.busy": "2024-04-17T04:13:51.016045Z",
     "iopub.status.idle": "2024-04-17T04:16:01.390161Z",
     "shell.execute_reply": "2024-04-17T04:16:01.388945Z",
     "shell.execute_reply.started": "2024-04-17T04:13:51.016354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting mosestokenizer\n",
      "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from mosestokenizer) (0.6.2)\n",
      "Collecting openfile (from mosestokenizer)\n",
      "  Downloading openfile-0.0.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting uctools (from mosestokenizer)\n",
      "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting toolwrapper (from mosestokenizer)\n",
      "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
      "Building wheels for collected packages: mosestokenizer, toolwrapper, uctools\n",
      "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49170 sha256=15e420c923ff4fae884e8b7bdf95d0360d6e6fc9c33b6f7313c41b20de4e5d9a\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/d8/15/4c5ebbe883513f003cb055a0369c77c9df857023a706f39e70\n",
      "  Building wheel for toolwrapper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3338 sha256=1f89c32cab90e1902e4c6d4b836736215bb387084fb36fe0a35403086b95d081\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n",
      "  Building wheel for uctools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6147 sha256=0a0c7f26555ca3a78b5d8f8985a20c362fcd42dbf314c84d3a72b541c4388539\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/ee/10/33257b0801ac6a912c841939032c16da1eb3db377afe1443e5\n",
      "Successfully built mosestokenizer toolwrapper uctools\n",
      "Installing collected packages: toolwrapper, openfile, uctools, mosestokenizer\n",
      "Successfully installed mosestokenizer-1.2.1 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=5a1dc58d9279095e49177bfee31d8825c4a1263f2b74f13ebd330802b4cb948e\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Cloning into 'IndicTransTokenizer'...\n",
      "remote: Enumerating objects: 123, done.\u001b[K\n",
      "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
      "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
      "remote: Total 123 (delta 52), reused 94 (delta 31), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (123/123), 3.85 MiB | 17.01 MiB/s, done.\n",
      "Resolving deltas: 100% (52/52), done.\n",
      "/kaggle/working/IndicTransTokenizer\n",
      "Obtaining file:///kaggle/working/IndicTransTokenizer\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library (from IndicTransTokenizer==0.1.3)\n",
      "  Cloning https://github.com/VarunGumma/indic_nlp_library to /tmp/pip-install-ch1f__uj/indic-nlp-library-it2_60a6c2805e124e4ba362fc01a8d3ac04\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library /tmp/pip-install-ch1f__uj/indic-nlp-library-it2_60a6c2805e124e4ba362fc01a8d3ac04\n",
      "  Resolved https://github.com/VarunGumma/indic_nlp_library to commit 09d30a15286cc252a12682e5450c807379717eaf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setuptools==68.2.2 (from IndicTransTokenizer==0.1.3)\n",
      "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (2.1.2)\n",
      "Collecting sacremoses (from IndicTransTokenizer==0.1.3)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (0.2.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (4.39.3)\n",
      "Collecting sacrebleu==2.3.1 (from IndicTransTokenizer==0.1.3)\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (1.26.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (5.2.1)\n",
      "Collecting sphinx-argparse (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: sphinx_rtd_theme in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (0.2.4)\n",
      "Collecting morfessor (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.1.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (4.66.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->IndicTransTokenizer==0.1.3) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->IndicTransTokenizer==0.1.3) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (2024.2.2)\n",
      "Collecting sphinx>=1.2.0 (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinx-7.3.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->IndicTransTokenizer==0.1.3) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (1.16.0)\n",
      "Collecting sphinxcontrib-applehelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting sphinxcontrib-qthelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.17.2)\n",
      "Requirement already satisfied: docutils<0.22,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (0.20.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.14.0)\n",
      "Collecting alabaster~=0.7.14 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tomli>=2 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.0.1)\n",
      "Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading sphinx-7.3.5-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\n",
      "Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: indic-nlp-library-IT2\n",
      "  Building wheel for indic-nlp-library-IT2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for indic-nlp-library-IT2: filename=indic_nlp_library_IT2-0.0.2-py3-none-any.whl size=49537 sha256=52d08e4c5df7573d79f1d280f9276145f93fb42e98abd752cf22be8df5b0dbbe\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b6h7wv9p/wheels/e9/72/fa/bd9f19a3f2bacb50efcaf28b7ab89fe7ca539e35b75334befc\n",
      "Successfully built indic-nlp-library-IT2\n",
      "Installing collected packages: morfessor, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, setuptools, sacremoses, portalocker, imagesize, alabaster, sphinx, sacrebleu, sphinx-argparse, indic-nlp-library-IT2, IndicTransTokenizer\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.0.3\n",
      "    Uninstalling setuptools-69.0.3:\n",
      "      Successfully uninstalled setuptools-69.0.3\n",
      "  Running setup.py develop for IndicTransTokenizer\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed IndicTransTokenizer-0.1.3 alabaster-0.7.16 imagesize-1.4.1 indic-nlp-library-IT2-0.0.2 morfessor-2.0.6 portalocker-2.8.2 sacrebleu-2.3.1 sacremoses-0.1.1 setuptools-68.2.2 sphinx-7.3.5 sphinx-argparse-0.4.0 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate\n",
    "%pip install nltk\n",
    "%pip install mosestokenizer\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
    "%cd IndicTransTokenizer\n",
    "!pip install --editable /kaggle/working/IndicTransTokenizer\n",
    "!pip install torch\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:01.392397Z",
     "iopub.status.busy": "2024-04-17T04:16:01.392098Z",
     "iopub.status.idle": "2024-04-17T04:16:02.323462Z",
     "shell.execute_reply": "2024-04-17T04:16:02.322602Z",
     "shell.execute_reply.started": "2024-04-17T04:16:01.392370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading.. /kaggle/input/test-data/test.mr\n",
      "reading.. /kaggle/input/test-data/test.hi\n",
      "reading.. /kaggle/input/test-data/test.en\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "sentences=[]\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        print(\"reading..\",path)\n",
    "        with open(path,'r',encoding='utf-8') as file:\n",
    "            text = file.readlines()\n",
    "            text = [x.strip().replace('\\u200d', '') for x in text]\n",
    "        temp = []\n",
    "        for line in text:\n",
    "            temp.append(line)\n",
    "        sentences.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:02.324801Z",
     "iopub.status.busy": "2024-04-17T04:16:02.324428Z",
     "iopub.status.idle": "2024-04-17T04:16:02.331747Z",
     "shell.execute_reply": "2024-04-17T04:16:02.330850Z",
     "shell.execute_reply.started": "2024-04-17T04:16:02.324777Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "indexes = random.sample(range(0,len(sentences[0])),1000)\n",
    "mar_sentences  = [sentences[0][i] for i in indexes]\n",
    "hi_sentences = [sentences[1][i] for i in indexes]\n",
    "eng_sentences = [sentences[2][i] for i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:02.334026Z",
     "iopub.status.busy": "2024-04-17T04:16:02.333738Z",
     "iopub.status.idle": "2024-04-17T04:16:02.342586Z",
     "shell.execute_reply": "2024-04-17T04:16:02.341774Z",
     "shell.execute_reply.started": "2024-04-17T04:16:02.334003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उन्होंने कहा कि श्री इनामदार ने इस सिद्धांत को अपने जीवन में आत्मसात किया था और उनका जीवन प्रेरणा का एक स्रोत है।', 'प्रधानमंत्री ने शिष्टमंडल के सदस्यों द्वारा पूछे गए विभिन्न प्रश्नों का विस्तार से जवाब दिया।', 'हमारे यूपीआई अथवा यूनाइटेड पेमेंट्स इंटरफेस सिस्टम के साथ-साथ भीम एप तथा रुपे कार्ड भी भारत में डिजिटल अर्थव्यवस्था की वास्तविक संभावनाओं को दर्शा रहे हैं।', 'आपदा पीड़ित लोगों को देखना पीड़ादायक होता है।', 'यह दोनों देशों की साझा सांस्कृतिक विरासत को ध्यान में रखते हुए दोनों देशों के लिए अत्यंत महत्वपूर्ण सिद्ध होगा।']\n",
      "['He said that Shri Inamdar had imbibed this principle, and his life is a source of inspiration.', 'The Prime Minister responded at length to various questions raised by the delegation members.', 'Our United Payments Interface system or UPI along with BHIM App and RuPay Card has shown the true potential of digital economy in India.', 'It was distressing to see the suffering of the affected people.', 'This will be of immense importance to both countries considering their shared cultural heritage.']\n",
      "['ते म्हणाले की, इनामदारांनी हे तत्व अंगीकारले आणि त्यांचे आयुष्य हे प्रेरणेचा स्रोत आहे.', 'शिष्टमंडळातील सदस्यांनी उपस्थित केलेल्या विविध प्रश्नांचे पंतप्रधानांनी सविस्तर निरसन केले.', 'आमच्या युनायटेड पेमेंट इंटरफेस सिस्टम किंवा यूपीआय, भीम अॅप आणि रुपे कार्डने भारतातील डिजिटल अर्थव्यवस्थेची खरी क्षमता दाखवली आहे.', 'या भूकंपाची झळ पोहोचलेल्या जनतेच्या हालअपेष्टा पाहणे अतिशय दुःखदायक होते.', 'दोन्ही देशातली सांस्कृतिक परंपरा लक्षात घेता हा सामंजस्य करार अतिशय महत्वाचा आहे.']\n"
     ]
    }
   ],
   "source": [
    "print(hi_sentences[:5])\n",
    "print(eng_sentences[:5])\n",
    "print(mar_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### writing dataset (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:02.343764Z",
     "iopub.status.busy": "2024-04-17T04:16:02.343541Z",
     "iopub.status.idle": "2024-04-17T04:16:02.355338Z",
     "shell.execute_reply": "2024-04-17T04:16:02.354442Z",
     "shell.execute_reply.started": "2024-04-17T04:16:02.343745Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"hi_sentences.txt\", \"w\",encoding='utf-8') as file:\n",
    "    for line in hi_sentences:\n",
    "        file.write(line+'\\n')\n",
    "with open(\"eng_sentences.txt\", \"w\",encoding='utf-8') as file:\n",
    "    for line in eng_sentences:\n",
    "        file.write(line+'\\n')\n",
    "with open(\"mar_sentences.txt\", \"w\",encoding='utf-8') as file:\n",
    "    for line in mar_sentences:\n",
    "        file.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If want to read from these files then use this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:02.356765Z",
     "iopub.status.busy": "2024-04-17T04:16:02.356406Z",
     "iopub.status.idle": "2024-04-17T04:16:02.361918Z",
     "shell.execute_reply": "2024-04-17T04:16:02.361044Z",
     "shell.execute_reply.started": "2024-04-17T04:16:02.356743Z"
    }
   },
   "outputs": [],
   "source": [
    "# def openFiles(filepath):\n",
    "#     with open(filepath, 'r',encoding='utf-8') as file:\n",
    "#         data = file.readlines()\n",
    "#         data = [line.strip().replace('\\u200d','') for line in data]\n",
    "#         return data\n",
    "# hi_sentences = openFiles(\"/kaggle/working/hi_sentences.txt\")\n",
    "# eng_sentences = openFiles(\"/kaggle/working/eng_sentences.txt\")\n",
    "# mar_sentences = openFiles(\"/kaggle/working/mar_sentences.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:02.363831Z",
     "iopub.status.busy": "2024-04-17T04:16:02.363108Z",
     "iopub.status.idle": "2024-04-17T04:16:02.372083Z",
     "shell.execute_reply": "2024-04-17T04:16:02.371175Z",
     "shell.execute_reply.started": "2024-04-17T04:16:02.363807Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(hi_sentences[:5])\n",
    "# print(eng_sentences[:5])\n",
    "# print(mar_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to compute required matrices->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:02.373688Z",
     "iopub.status.busy": "2024-04-17T04:16:02.373160Z",
     "iopub.status.idle": "2024-04-17T04:16:20.669242Z",
     "shell.execute_reply": "2024-04-17T04:16:20.668329Z",
     "shell.execute_reply.started": "2024-04-17T04:16:02.373658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:16:09.915822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-17 04:16:09.915917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-17 04:16:10.048245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from nltk.tokenize import word_tokenize\n",
    "def compute_matrice(predictions,references):\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    rogue = evaluate.load('rouge')\n",
    "    bleu_score = bleu.compute(predictions=predictions, references=references)\n",
    "    rogue_score = rogue.compute(predictions=predictions, references=references)\n",
    "    print(bleu_score)\n",
    "    print(\"=\"*15)\n",
    "    print(rogue_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:20.671328Z",
     "iopub.status.busy": "2024-04-17T04:16:20.670734Z",
     "iopub.status.idle": "2024-04-17T04:16:31.738232Z",
     "shell.execute_reply": "2024-04-17T04:16:31.737220Z",
     "shell.execute_reply.started": "2024-04-17T04:16:20.671299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c7f6f0807847b7a04d1b75e563c214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31af4a0bdc434160889ea4b542b0ef31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30695d7540634c2f86124d797430b1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34ba5960cf34071aeb016d211340f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5bd8c0fdd3423b9c0b77845a106ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59864c9ae25a4a21b4c65ba4f056a349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e124fc378d24d89a04066f1832b4034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use GPU if avail, otherwise CPU will be used by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:31.742002Z",
     "iopub.status.busy": "2024-04-17T04:16:31.741697Z",
     "iopub.status.idle": "2024-04-17T04:16:32.548469Z",
     "shell.execute_reply": "2024-04-17T04:16:32.547451Z",
     "shell.execute_reply.started": "2024-04-17T04:16:31.741977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CPU times: user 610 ms, sys: 148 ms, total: 758 ms\n",
      "Wall time: 801 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model=model.to(device)\n",
    "# (may give error if all tensors are not shifted to GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for translation from src_lang to tgt_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:32.549823Z",
     "iopub.status.busy": "2024-04-17T04:16:32.549530Z",
     "iopub.status.idle": "2024-04-17T04:16:32.557361Z",
     "shell.execute_reply": "2024-04-17T04:16:32.556512Z",
     "shell.execute_reply.started": "2024-04-17T04:16:32.549800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def translate_sentence(sentence, src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\"):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    #  tokenize the input sentence\n",
    "    translated_ids = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "    # Decode the tokens\n",
    "    translated_sentence = tokenizer.batch_decode(translated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return translated_sentence[0]\n",
    "\n",
    "def write_file(filename,sentences):\n",
    "    with open(filename,\"w\",encoding='utf-8') as file:\n",
    "        for sentence in sentences:\n",
    "            file.write(sentence+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:16:32.558708Z",
     "iopub.status.busy": "2024-04-17T04:16:32.558405Z",
     "iopub.status.idle": "2024-04-17T04:24:06.900590Z",
     "shell.execute_reply": "2024-04-17T04:24:06.899636Z",
     "shell.execute_reply.started": "2024-04-17T04:16:32.558686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the `lang_code_to_id` attribute is deprecated. The logic is natively handled in the `tokenizer.adder_tokens_decoder` this attribute will be removed in `transformers` v4.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उन्होंने कहा कि श्री इनामदार ने इस सिद्धांत को अपनाया है और उनका जीवन प्रेरणा का स्रोत है।', 'प्रधानमंत्री ने प्रतिनिधिमंडल के सदस्यों द्वारा उठाए गए विभिन्न सवालों के विस्तार से जवाब दिए।', 'हमारी यूनाइटेड पेमेंट्स इंटरफेस प्रणाली या यूपीआई भीम ऐप और रूपई कार्ड के साथ भारत में डिजिटल अर्थव्यवस्था की वास्तविक क्षमता को दिखा रही है।', 'पीड़ित लोगों के दुख को देखना दुखद था।', 'दोनों देशों के लिए यह बहुत महत्वपूर्ण होगा क्योंकि दोनों देश अपनी साझा सांस्कृतिक विरासत को देखते हैं।']\n",
      "\n",
      " Blue and rogue Scores for eng to hi translation by NLLB:\n",
      "===============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1e066e071d41d9ba1cad48fea76a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c4eb8d562245629ad04ccc41f3d49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3373d46e40c04c0d9c98e43c7846845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e229a62a0848019f1e6a173fdb795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.3214126874851807, 'precisions': [0.6341702741702742, 0.39822358346094944, 0.2699334464309017, 0.18671040692398966], 'brevity_penalty': 0.9569152934477807, 'length_ratio': 0.9578173374613003, 'translation_length': 17325, 'reference_length': 18088}\n",
      "===============\n",
      "{'rouge1': 0.12157619047619046, 'rouge2': 0.029000000000000005, 'rougeL': 0.12095952380952382, 'rougeLsum': 0.12096190476190477}\n",
      "CPU times: user 7min 28s, sys: 3.81 s, total: 7min 32s\n",
      "Wall time: 7min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===================English to Hindi==========================\n",
    "en_2_hi_sentences_nllb = []\n",
    "for sentence in eng_sentences:\n",
    "    en_2_hi_sentences_nllb.append(translate_sentence(sentence,src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\"))\n",
    "print(en_2_hi_sentences_nllb[:5])\n",
    "print(\"\\n Blue and rogue Scores for eng to hi translation by NLLB:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where en_2_hi_sentences_nllb is translated hi sentence by nllb and hi_sentences are original sentences\n",
    "compute_matrice(en_2_hi_sentences_nllb,hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:24:06.902593Z",
     "iopub.status.busy": "2024-04-17T04:24:06.902162Z",
     "iopub.status.idle": "2024-04-17T04:31:27.308032Z",
     "shell.execute_reply": "2024-04-17T04:31:27.306979Z",
     "shell.execute_reply.started": "2024-04-17T04:24:06.902555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He said that Shri Inamdar had incorporated this principle into his life and his life is a source of inspiration.', 'The Prime Minister answered various questions asked by the delegation members in detail.', 'Along with our UPI or United Payments Interface System, BHIM App and Rupee Card are also showing the real potential of the digital economy in India.', 'It is painful to see people suffering from disasters.', 'This will prove to be extremely important for both countries, taking into account the shared cultural heritage of both countries.']\n",
      "\n",
      " Blue and rogue Scores for hi to eng translation by NLLB:\n",
      "===============\n",
      "{'bleu': 0.3635644843798687, 'precisions': [0.6629207169747711, 0.42501637197118536, 0.29600557067797684, 0.20948776861738072], 'brevity_penalty': 1.0, 'length_ratio': 1.0045154371507592, 'translation_length': 17797, 'reference_length': 17717}\n",
      "===============\n",
      "{'rouge1': 0.6820677456843711, 'rouge2': 0.4591287514619859, 'rougeL': 0.6360717354972417, 'rougeLsum': 0.6358223571072656}\n",
      "CPU times: user 7min 15s, sys: 3.9 s, total: 7min 18s\n",
      "Wall time: 7min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===================Hindi to English==========================\n",
    "hi_2_en_sentences_nllb = []\n",
    "for sentence in hi_sentences:\n",
    "    hi_2_en_sentences_nllb.append(translate_sentence(sentence,src_lang=\"hin_Deva\", tgt_lang=\"eng_Latn\"))\n",
    "print(hi_2_en_sentences_nllb[:5])\n",
    "print(\"\\n Blue and rogue Scores for hi to eng translation by NLLB:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where hi_2_en_sentences_nllb is translated eng sentence by nllb and eng_sentences are original sentences\n",
    "compute_matrice(hi_2_en_sentences_nllb,eng_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:31:27.310076Z",
     "iopub.status.busy": "2024-04-17T04:31:27.309673Z",
     "iopub.status.idle": "2024-04-17T04:38:56.406261Z",
     "shell.execute_reply": "2024-04-17T04:38:56.405282Z",
     "shell.execute_reply.started": "2024-04-17T04:31:27.310038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उन्होंने कहा कि पुरस्कारदाताओं ने इस तत्व को अपनाया है और उनका जीवन प्रेरणा का स्रोत है।', 'प्रधानमंत्री ने प्रतिनिधिमंडल के सदस्यों द्वारा उपस्थित विभिन्न प्रश्नों का विस्तृत समाधान किया।', 'हमारे यूनाइटेड पेमेंट इंटरफेस सिस्टम या यूपीआई, भीम ऐप और रुपे कार्ड ने भारत की डिजिटल अर्थव्यवस्था की खरी क्षमता दिखाई है।', 'या भूकंप की झलक से प्रभावित लोगों की हालत को देखना बहुत दुखद होता है।', 'दोनों देशों की सांस्कृतिक परंपराओं को देखते हुए यह समझौता बहुत महत्वपूर्ण है।']\n",
      "\n",
      " Blue and rogue Scores for mar to hi translation by NLLB:\n",
      "===============\n",
      "{'bleu': 0.21083193639889194, 'precisions': [0.5382363274388101, 0.28790894389849486, 0.1646770128664279, 0.09808935293699837], 'brevity_penalty': 0.9425744086858198, 'length_ratio': 0.9441618752764264, 'translation_length': 17078, 'reference_length': 18088}\n",
      "===============\n",
      "{'rouge1': 0.1092404761904762, 'rouge2': 0.022, 'rougeL': 0.10882857142857144, 'rougeLsum': 0.10905952380952383}\n",
      "CPU times: user 7min 24s, sys: 3.66 s, total: 7min 27s\n",
      "Wall time: 7min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===================Marathi to Hindi==========================\n",
    "mar_2_hi_sentences_nllb = []\n",
    "for sentence in mar_sentences:\n",
    "    mar_2_hi_sentences_nllb.append(translate_sentence(sentence,src_lang=\"mar_Deva\", tgt_lang=\"hin_Deva\"))\n",
    "print(mar_2_hi_sentences_nllb[:5])\n",
    "print(\"\\n Blue and rogue Scores for mar to hi translation by NLLB:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where mar_2_hi_sentences_nllb is translated mar sentence by nllb and hi_sentences are original sentences\n",
    "compute_matrice(mar_2_hi_sentences_nllb,hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:38:56.407896Z",
     "iopub.status.busy": "2024-04-17T04:38:56.407576Z",
     "iopub.status.idle": "2024-04-17T04:46:48.356989Z",
     "shell.execute_reply": "2024-04-17T04:46:48.355983Z",
     "shell.execute_reply.started": "2024-04-17T04:38:56.407871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['श्री इनामदार यांनी हा सिद्धांत आपल्या जीवनात आत्मसात केला आणि त्यांचे जीवन प्रेरणादायी आहे, असे ते म्हणाले.', 'शिष्टमंडळातील सदस्यांनी उपस्थित केलेल्या विविध प्रश्नांची पंतप्रधानांनी उत्तरे दिली.', 'आमच्या यूपीआय किंवा युनायटेड पेमेंट्स इंटरफेस सिस्टमसोबतच भीम अॅप आणि रुपे कार्ड देखील भारतात डिजिटल अर्थव्यवस्थेच्या वास्तविक शक्यता दर्शवत आहेत.', 'आपत्ती पीडित लोकांना पाहणे वेदनादायक असते.', 'दोन्ही देशांच्या सामायिक सांस्कृतिक वारसा लक्षात घेऊन दोन्ही देशांसाठी हे अत्यंत महत्त्वाचे ठरेल.']\n",
      "\n",
      " Blue and rogue Scores for hi to mar translation by NLLB:\n",
      "===============\n",
      "{'bleu': 0.15616568865017624, 'precisions': [0.47098467650397274, 0.21747098350641417, 0.10953128874927669, 0.058733447437167824], 'brevity_penalty': 0.9747150548278938, 'length_ratio': 0.975029397523691, 'translation_length': 14096, 'reference_length': 14457}\n",
      "===============\n",
      "{'rouge1': 0.08963333333333333, 'rouge2': 0.015666666666666666, 'rougeL': 0.08828333333333334, 'rougeLsum': 0.08831666666666668}\n",
      "CPU times: user 7min 47s, sys: 3.11 s, total: 7min 50s\n",
      "Wall time: 7min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ===================Hindi to Marathi==========================\n",
    "hi_2_mar_sentences_nllb = []\n",
    "for sentence in hi_sentences:\n",
    "    hi_2_mar_sentences_nllb.append(translate_sentence(sentence,src_lang=\"hin_Deva\", tgt_lang=\"mar_Deva\"))\n",
    "print(hi_2_mar_sentences_nllb[:5])\n",
    "print(\"\\n Blue and rogue Scores for hi to mar translation by NLLB:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where mar_2_hi_sentences_nllb is translated mar sentence by nllb and hi_sentences are original sentences\n",
    "compute_matrice(hi_2_mar_sentences_nllb,mar_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uncomment if you want to dump these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:46:48.358949Z",
     "iopub.status.busy": "2024-04-17T04:46:48.358574Z",
     "iopub.status.idle": "2024-04-17T04:46:48.369295Z",
     "shell.execute_reply": "2024-04-17T04:46:48.368368Z",
     "shell.execute_reply.started": "2024-04-17T04:46:48.358915Z"
    }
   },
   "outputs": [],
   "source": [
    "write_file(\"en_2_hi_sentences_nllb.txt\",en_2_hi_sentences_nllb)\n",
    "write_file(\"hi_2_en_sentences_nllb.txt\",hi_2_en_sentences_nllb)\n",
    "write_file(\"mar_2_hi_sentences_nllb.txt\",hi_2_en_sentences_nllb)\n",
    "write_file(\"hi_2_mar_sentences_nllb.txt\",hi_2_en_sentences_nllb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndicTrans Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:46:48.371110Z",
     "iopub.status.busy": "2024-04-17T04:46:48.370851Z",
     "iopub.status.idle": "2024-04-17T04:46:48.913821Z",
     "shell.execute_reply": "2024-04-17T04:46:48.912897Z",
     "shell.execute_reply.started": "2024-04-17T04:46:48.371087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 485 ms, sys: 13 ms, total: 498 ms\n",
      "Wall time: 527 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "import torch\n",
    "from IndicTransTokenizer import IndicTransTokenizer, IndicProcessor\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from mosestokenizer import MosesSentenceSplitter\n",
    "from nltk import sent_tokenize\n",
    "from indicnlp.tokenize.sentence_tokenize import sentence_split, DELIM_PAT_NO_DANDA\n",
    "\n",
    "\n",
    "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"  \n",
    "indic_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-dist-200M\"  \n",
    "indic_indic_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-dist-320M\" \n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    quantization = sys.argv[1]\n",
    "else:\n",
    "    quantization = \"\"\n",
    "\n",
    "def split_sentences(input_text, lang):\n",
    "    if lang == \"eng_Latn\":\n",
    "        input_sentences = sent_tokenize(input_text)\n",
    "        with MosesSentenceSplitter(flores_codes[lang]) as splitter:\n",
    "            sents_moses = splitter([input_text])\n",
    "        sents_nltk = sent_tokenize(input_text)\n",
    "        if len(sents_nltk) < len(sents_moses):\n",
    "            input_sentences = sents_nltk\n",
    "        else:\n",
    "            input_sentences = sents_moses\n",
    "        input_sentences = [sent.replace(\"\\xad\", \"\") for sent in input_sentences]\n",
    "    else:\n",
    "        input_sentences = sentence_split(input_text, lang=flores_codes[lang], delim_pat=DELIM_PAT_NO_DANDA)\n",
    "    return input_sentences\n",
    "\n",
    "\n",
    "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = IndicTransTokenizer(direction=direction)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        # model.half() gpu\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    translations = []\n",
    "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            src=True,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Generate translations using the model\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decodeing the generated tokens into text\n",
    "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
    "\n",
    "        # Postprocessing the translations, including entity replacement\n",
    "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intializing models and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:46:48.915670Z",
     "iopub.status.busy": "2024-04-17T04:46:48.915004Z",
     "iopub.status.idle": "2024-04-17T04:47:05.756969Z",
     "shell.execute_reply": "2024-04-17T04:47:05.756037Z",
     "shell.execute_reply.started": "2024-04-17T04:46:48.915643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc423930a1444e13a52150e7262687cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5408efea8d2946bbb8053ee987348462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b0ecdf71c44d83b80558a887269fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23164fab642747099289550d00fdaae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc357bb098847629dd40a79b219aff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0483624a757466781ab29993b7621d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1b275cea834174a2b13a006ba26fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9ac2e8f71f4eaaa744443a4ba8a113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e63c310ccd43659f51913cc4109bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/914M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746738bbfbde412fb26046fff86cb1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899ad790652942d0b9a84e19525de7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f7376f3e224a61a1a75e8e2e766644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497791ef87b04beea3b7098131d0de61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835cb3edddd74c068def88a0b7685a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2d0f4d6da54b6d99b412497becdeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
    "indic_en_tokenizer, indic_en_model = initialize_model_and_tokenizer(indic_en_ckpt_dir, \"indic-en\", quantization)\n",
    "indic_indic_tokenizer, indic_indic_model = initialize_model_and_tokenizer(indic_indic_ckpt_dir, \"indic-indic\", quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:47:05.758483Z",
     "iopub.status.busy": "2024-04-17T04:47:05.758151Z",
     "iopub.status.idle": "2024-04-17T04:50:19.759228Z",
     "shell.execute_reply": "2024-04-17T04:50:19.758229Z",
     "shell.execute_reply.started": "2024-04-17T04:47:05.758447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उन्होंने कहा कि श्री इनामदार ने इस सिद्धांत को अपनाया था और उनका जीवन प्रेरणा का स्रोत है।', 'प्रधानमंत्री ने प्रतिनिधिमंडल के सदस्यों द्वारा उठाए गए विभिन्न प्रश्नों का विस्तार से उत्तर दिया।', 'भीम ऐप और रुपे कार्ड के साथ हमारी यूनाइटेड पेमेंट्स इंटरफेस सिस्टम या यू. पी. आई. ने भारत में डिजिटल अर्थव्यवस्था की वास्तविक क्षमता को दिखाया है।', 'प्रभावित लोगों की पीड़ा को देखना दुखद था।', 'दोनों देशों की साझा सांस्कृतिक विरासत को देखते हुए यह दोनों देशों के लिए बहुत महत्वपूर्ण होगा।']\n",
      "\n",
      " Blue and rogue Scores for eng to hi translation by IndicTranse:\n",
      "===============\n",
      "{'bleu': 0.3620301184204696, 'precisions': [0.6457446220206824, 0.42451560030439617, 0.29638149714001494, 0.21166721909181305], 'brevity_penalty': 0.999723535430696, 'length_ratio': 0.9997235736399823, 'translation_length': 18083, 'reference_length': 18088}\n",
      "===============\n",
      "{'rouge1': 0.11841648351648354, 'rouge2': 0.02362943722943723, 'rougeL': 0.11796355311355312, 'rougeLsum': 0.1177423076923077}\n",
      "CPU times: user 3min 6s, sys: 5.97 s, total: 3min 12s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ============================English to Hindi====================================\n",
    "en_2_hindi_IndicTrans = []\n",
    "en_2_hindi_IndicTrans = batch_translate(eng_sentences, \"eng_Latn\", \"hin_Deva\", en_indic_model, en_indic_tokenizer, ip)\n",
    "print(en_2_hindi_IndicTrans[:5])\n",
    "print(\"\\n Blue and rogue Scores for eng to hi translation by IndicTranse:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where en_2_hindi_IndicTrans is translated hi sentence by IndicTranse and hi_sentences are original sentences\n",
    "compute_matrice(en_2_hindi_IndicTrans,hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:50:19.760659Z",
     "iopub.status.busy": "2024-04-17T04:50:19.760367Z",
     "iopub.status.idle": "2024-04-17T04:53:24.388828Z",
     "shell.execute_reply": "2024-04-17T04:53:24.387799Z",
     "shell.execute_reply.started": "2024-04-17T04:50:19.760635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He said that Shri Inamdar had imbibed this principle in his life and his life is a source of inspiration.', 'The Prime Minister answered various questions posed by the members of the delegation in detail.', 'Our UPI or United Payments Interface system, as well as the BHIM app and RuPay cards, are also showing the real potential of the digital economy in India.', 'It is painful to see people affected by a disaster.', 'This will prove to be extremely important for both the countries considering the shared cultural heritage of both the countries.']\n",
      "\n",
      " Blue and rogue Scores for hi to eng translation by IndicTranse:\n",
      "===============\n",
      "{'bleu': 0.4107323138301978, 'precisions': [0.6907308377896613, 0.4682633317602643, 0.3431956371842287, 0.25638625117025543], 'brevity_penalty': 1.0, 'length_ratio': 1.013264096630355, 'translation_length': 17952, 'reference_length': 17717}\n",
      "===============\n",
      "{'rouge1': 0.7220278572365707, 'rouge2': 0.5162517617918585, 'rougeL': 0.6765146861920868, 'rougeLsum': 0.6762723758196599}\n"
     ]
    }
   ],
   "source": [
    "# ============================Hindi to English====================================\n",
    "hindi_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-dist-200M\"\n",
    "hi_2_en_IndicTrans = batch_translate(hi_sentences, \"hin_Deva\", \"eng_Latn\", indic_en_model, indic_en_tokenizer, ip)\n",
    "print(hi_2_en_IndicTrans[:5])\n",
    "print(\"\\n Blue and rogue Scores for hi to eng translation by IndicTranse:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where hi_2_en_IndicTrans is translated English sentence by IndicTranse and eng_sentences are original sentences\n",
    "compute_matrice(hi_2_en_IndicTrans, eng_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:53:24.390847Z",
     "iopub.status.busy": "2024-04-17T04:53:24.390399Z",
     "iopub.status.idle": "2024-04-17T04:56:36.511201Z",
     "shell.execute_reply": "2024-04-17T04:56:36.510159Z",
     "shell.execute_reply.started": "2024-04-17T04:53:24.390804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उन्होंने कहा कि इनामदारों ने इस सिद्धांत को अपनाया और उनका जीवन प्रेरणा का स्रोत है।', 'प्रधानमंत्री ने प्रतिनिधिमंडल के सदस्यों द्वारा उठाए गए विभिन्न प्रश्नों का विस्तार से समाधान किया।', 'हमारी संयुक्त भुगतान इंटरफेस प्रणाली या यूपीआई, भीम ऐप और रुपे कार्ड ने भारत में डिजिटल अर्थव्यवस्था की वास्तविक क्षमता को दिखाया है।', 'भूकंप से प्रभावित लोगों की पीड़ा को देखना बहुत दुखद था।', 'दोनों देशों की सांस्कृतिक परंपराओं को देखते हुए यह समझौता ज्ञापन बहुत महत्वपूर्ण है।']\n",
      "\n",
      " Blue and rogue Scores for mr to hi translation by IndicTranse:\n",
      "===============\n",
      "{'bleu': 0.24581565656953122, 'precisions': [0.5512290502793296, 0.30940828402366866, 0.1882900446512798, 0.11857468796134747], 'brevity_penalty': 0.9895521684518365, 'length_ratio': 0.9896063688633349, 'translation_length': 17900, 'reference_length': 18088}\n",
      "===============\n",
      "{'rouge1': 0.11039285714285715, 'rouge2': 0.022333333333333334, 'rougeL': 0.11047619047619048, 'rougeLsum': 0.11027619047619047}\n"
     ]
    }
   ],
   "source": [
    "# ============================Marathi to Hindi====================================\n",
    "marathi_hindi_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-dist-320M\"\n",
    "mar_2_hindi_IndicTrans = batch_translate(mar_sentences, \"mar_Deva\", \"hin_Deva\", indic_indic_model, indic_indic_tokenizer, ip)\n",
    "print(mar_2_hindi_IndicTrans[:5])\n",
    "print(\"\\n Blue and rogue Scores for mr to hi translation by IndicTranse:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where mar_2_hindi_IndicTrans is translated hi sentence by IndicTranse and hi_sentences are original sentences\n",
    "compute_matrice(mar_2_hindi_IndicTrans, hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:56:36.513108Z",
     "iopub.status.busy": "2024-04-17T04:56:36.512828Z",
     "iopub.status.idle": "2024-04-17T04:59:40.285599Z",
     "shell.execute_reply": "2024-04-17T04:59:40.284531Z",
     "shell.execute_reply.started": "2024-04-17T04:56:36.513084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ते म्हणाले की श्री. इनामदार यांनी त्यांच्या जीवनात हा सिद्धांत आत्मसात केला होता आणि त्यांचे जीवन हा प्रेरणेचा स्रोत आहे.', 'शिष्टमंडळाच्या सदस्यांनी विचारलेल्या विविध प्रश्नांना पंतप्रधानांनी सविस्तर उत्तर दिले.', 'आमची यू. पी. आय. किंवा युनायटेड पेमेंट्स इंटरफेस प्रणाली तसेच भीम अॅप आणि रुपे कार्ड देखील भारतातील डिजिटल अर्थव्यवस्थेची खरी शक्यता दर्शवित आहेत.', 'आपत्तीग्रस्त लोकांना पाहणे वेदनादायक आहे.', 'दोन्ही देशांचा सामायिक सांस्कृतिक वारसा लक्षात घेता हे दोन्ही देशांसाठी अत्यंत महत्त्वाचे ठरेल.']\n",
      "\n",
      " Blue and rogue Scores for hi to mr translation by IndicTranse:\n",
      "===============\n",
      "{'bleu': 0.15953046903355353, 'precisions': [0.4663871229541458, 0.21782968228637747, 0.10909517478689294, 0.05843935538592027], 'brevity_penalty': 1.0, 'length_ratio': 1.0227571418689907, 'translation_length': 14786, 'reference_length': 14457}\n",
      "===============\n",
      "{'rouge1': 0.09161666666666668, 'rouge2': 0.01873333333333333, 'rougeL': 0.09115238095238096, 'rougeLsum': 0.09129999999999999}\n"
     ]
    }
   ],
   "source": [
    "# ============================Hindi to Marathi====================================\n",
    "hindi_marathi_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-dist-320M\"\n",
    "hi_2_marathi_IndicTrans = batch_translate(hi_sentences, \"hin_Deva\", \"mar_Deva\", indic_indic_model, indic_indic_tokenizer, ip)\n",
    "print(hi_2_marathi_IndicTrans[:5])\n",
    "print(\"\\n Blue and rogue Scores for hi to mr translation by IndicTranse:\")\n",
    "print(\"=\"*15)\n",
    "\n",
    "# Calculating required matrices where hi_2_marathi_IndicTrans is translated Marathi sentence by IndicTranse and mar_sentences are original sentences\n",
    "compute_matrice(hi_2_marathi_IndicTrans, mar_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to dump these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T04:59:40.287118Z",
     "iopub.status.busy": "2024-04-17T04:59:40.286818Z",
     "iopub.status.idle": "2024-04-17T04:59:40.297396Z",
     "shell.execute_reply": "2024-04-17T04:59:40.296412Z",
     "shell.execute_reply.started": "2024-04-17T04:59:40.287087Z"
    }
   },
   "outputs": [],
   "source": [
    "write_file(\"en_2_hindi_IndicTrans.txt\",en_2_hindi_IndicTrans)\n",
    "write_file(\"hi_2_en_IndicTrans.txt\",hi_2_en_IndicTrans)\n",
    "write_file(\"mar_2_hindi_IndicTrans.txt\",mar_2_hindi_IndicTrans)\n",
    "write_file(\"hi_2_marathi_IndicTrans.txt\",hi_2_marathi_IndicTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4810437,
     "sourceId": 8137147,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
