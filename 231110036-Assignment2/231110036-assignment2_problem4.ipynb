{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b412c6",
   "metadata": {},
   "source": [
    "# Problem-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d404513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88167f66",
   "metadata": {},
   "source": [
    "## Function to return predicted 'ner' labels for each tokenizer and Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4992bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions( sentence, tokenizer, model ):\n",
    "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**tok_sentence).logits.argmax(-1)\n",
    "\n",
    "        predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
    "                previous_token_id = word_ids[word_index]\n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555a281",
   "metadata": {},
   "source": [
    "### Function to return required accuracy matrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3bdd170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    true_labels_flat = [label for sublist in true_labels for label in sublist]\n",
    "    predicted_labels_flat = [label for sublist in predicted_labels for label in sublist]\n",
    "    \n",
    "    #because manual labelling and different tokenizer can can generate different length token lists \n",
    "    minlen = min(len(true_labels_flat),len(predicted_labels_flat))\n",
    "    true_labels_flat = true_labels_flat[:minlen]\n",
    "    predicted_labels_flat = predicted_labels_flat[:minlen]\n",
    "    \n",
    "    precision = precision_score(true_labels_flat, predicted_labels_flat, average='weighted')\n",
    "    recall = recall_score(true_labels_flat, predicted_labels_flat, average='weighted')\n",
    "    f1 = f1_score(true_labels_flat, predicted_labels_flat, average='weighted')\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d9ab9",
   "metadata": {},
   "source": [
    "### List 'sentences' contains all 25 sentences assigned to me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ada164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'raw_sentences_file.txt' \n",
    "sentences = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            sentences.append(line[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067348a0",
   "metadata": {},
   "source": [
    "###  List 'manual_labels' contains 'ner' labels manually assigned to these 25 sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc99f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "file_path = 'manual_ner_file.txt'  \n",
    "manual_labels =[]\n",
    "NER_labels = ['O', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        labels = [tag.strip().strip(\"'\") for tag in line.split(' ')]  \n",
    "        labels = [tag for tag in labels if tag in NER_labels]\n",
    "        if labels:\n",
    "            manual_labels.append(labels)\n",
    "print(manual_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf618b",
   "metadata": {},
   "source": [
    "### Scores For Finetuned Indic_ner Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05daa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First senetence:\n",
      "आपात्काल मे धेेैर्य , अभ्युदय मे क्षमा , सदन मे वाक्पटुता , युद्ध के समय बहादुरी , यशमे अभिरूचि , ज्ञान का व्यसन ये सब चीजे महापुरूषोंमे नैसर्गिक रूपसे पायी जाती हैं ।\n",
      "Predicted labels for first sentence:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Comparison in manual labels and predicted labels:\n",
      "==================================================\n",
      "Precision: 0.8731, Recall: 0.8588, Macro-F1: 0.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\ml_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"finetunedINDIC_ner_model\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Printing first sentence\n",
    "print(\"First senetence:\")\n",
    "print(sentences[0])\n",
    "\n",
    "predicted_labels = []\n",
    "for sentence in sentences:\n",
    "    pred_labels = get_predictions(sentence=sentence, tokenizer=tokenizer,model=model)\n",
    "    predicted_labels.append(pred_labels)\n",
    "\n",
    "print(\"Predicted labels for first sentence:\")\n",
    "print(predicted_labels[0])\n",
    "\n",
    "print(\"Comparison in manual labels and predicted labels:\")\n",
    "print(\"=\"*50)\n",
    "precision, recall, f1 = calculate_metrics(manual_labels, predicted_labels)\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Macro-F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e8a5f",
   "metadata": {},
   "source": [
    "### Scores For Finetuned Indic_BERT Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b96fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third senetence:\n",
      "कहने की जरूरत नहीं कि मुकेश चौरसिया मीडियाखबर डॉट कॉम नाम के एक पोर्टल का सहयोगी है और मीडियाखबर नामक पोर्टल का मालिक है पुष्‍कर पुष्‍प।\n",
      "Predicted labels for third sentence:\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Comparison in manual labels and predicted labels:\n",
      "==================================================\n",
      "Precision: 0.8182, Recall: 0.8128, Macro-F1: 0.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\ml_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\envs\\ml_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"finetunedBERT_ner_model\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path,num_labels=7)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "print(\"Third senetence:\")\n",
    "print(sentences[2])\n",
    "\n",
    "predicted_labels = []\n",
    "for sentence in sentences:\n",
    "    pred_labels = get_predictions(sentence=sentence, tokenizer=tokenizer,model=model)\n",
    "    predicted_labels.append(pred_labels)\n",
    "\n",
    "print(\"Predicted labels for third sentence:\")\n",
    "print(predicted_labels[2])\n",
    "\n",
    "print(\"Comparison in manual labels and predicted labels:\")\n",
    "print(\"=\"*50)\n",
    "precision, recall, f1 = calculate_metrics(manual_labels, predicted_labels)\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Macro-F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca6c06",
   "metadata": {},
   "source": [
    "### Predictions from ChatGPT, (collected in a text file namely 'ChatGPT_ner_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6d4680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison in manual labels and predicted labels:\n",
      "==================================================\n",
      "Precision: 0.8435, Recall: 0.8148, Macro-F1: 0.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\ml_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "file_path = 'ChatGPT_ner_file.txt' \n",
    "predicted_labels =[]\n",
    "NER_labels = ['O', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        labels = [tag.strip().strip(\"'\") for tag in line.split(' ')]  \n",
    "        labels = [tag for tag in labels if tag in NER_labels]\n",
    "        if labels:\n",
    "            predicted_labels.append(labels)\n",
    "        \n",
    "print(\"Comparison in manual labels and predicted labels:\")\n",
    "print(\"=\"*50)\n",
    "precision, recall, f1 = calculate_metrics(manual_labels, predicted_labels)\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Macro-F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34ba39",
   "metadata": {},
   "source": [
    "## Example of Prediction for question 5, (img attached in pdf):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbceb13",
   "metadata": {},
   "source": [
    "### Example for Indic_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "445683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finetunedINDIC_ner_model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"finetunedINDIC_ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84f10617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O']\n",
      "अभिनेत्री\tO\n",
      "सोहा\tB-PER\n",
      "अली\tI-PER\n",
      "खान\tI-PER\n",
      "से\tO\n",
      "उनकी\tO\n",
      "मां\tO\n",
      "अभिनेत्री\tO\n",
      "शर्मिला\tB-PER\n",
      "टैगोर\tI-PER\n",
      "खासी\tO\n",
      "नाराज़\tO\n",
      "हैं.\tO\n"
     ]
    }
   ],
   "source": [
    "sentence = 'अभिनेत्री सोहा अली खान से उनकी मां अभिनेत्री शर्मिला टैगोर खासी नाराज़ हैं.'\n",
    "\n",
    "predicted_labels = get_predictions(sentence=sentence, \n",
    "                                   tokenizer=tokenizer,\n",
    "                                   model=model\n",
    "                                   )\n",
    "print(predicted_labels)\n",
    "for index in range(len(sentence.split(' '))):\n",
    "  print( sentence.split(' ')[index] + '\\t' + predicted_labels[index] )\n",
    "predicted_labels = [i.strip(',') for i in predicted_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc2efc",
   "metadata": {},
   "source": [
    "### Example for IndicBERT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6af8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finetunedBERT_ner_model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"finetunedBERT_ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca3e268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "लोकसभा\tO\n",
      "में\tO\n",
      "कांग्रेस\tB-LOC\n",
      "नेता\tO\n",
      "मलिक्कार्जुन\tB-PER\n",
      "खड़गे\tI-PER\n",
      "ने\tO\n",
      "कहा\tO\n",
      "कि\tO\n",
      "प्रधानमंत्री\tO\n",
      "नरेंद्र\tB-PER\n",
      "मोदी\tI-PER\n",
      "भारत\tB-ORG\n",
      "के\tO\n",
      "साथ\tO\n",
      "वही\tO\n",
      "करना\tO\n",
      "चाहते\tO\n",
      "हैं\tO\n"
     ]
    }
   ],
   "source": [
    "sentence = 'लोकसभा में कांग्रेस नेता मलिक्कार्जुन खड़गे ने कहा कि प्रधानमंत्री नरेंद्र मोदी भारत के साथ वही करना चाहते हैं'\n",
    "\n",
    "predicted_labels = get_predictions(sentence=sentence, \n",
    "                                   tokenizer=tokenizer,\n",
    "                                   model=model\n",
    "                                   )\n",
    "print(predicted_labels)\n",
    "for index in range(len(sentence.split(' '))):\n",
    "  print( sentence.split(' ')[index] + '\\t' + predicted_labels[index] )\n",
    "predicted_labels = [i.strip(',') for i in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e867cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
